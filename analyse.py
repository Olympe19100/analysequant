import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from statsmodels.tsa.stattools import adfuller, grangercausalitytests, coint
from sklearn.feature_selection import mutual_info_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score
import plotly.graph_objects as go
import streamlit as st
import statsmodels.api as sm  # Assurez-vous que cette ligne est pr√©sente en haut de votre code
import scipy.stats as stats

# D√©finir la classe d'analyse
class ComprehensiveCryptoCommoAnalyzer:
    def __init__(self, tickers, names, start_date):
        self.tickers = tickers
        self.names = names  # noms r√©els des actifs financiers
        self.start_date = start_date
        self.data = None
        self.returns = None
        self.significant_vars = []  # Pour stocker les variables significatives

    def fetch_data(self):
        """
        T√©l√©charge les donn√©es historiques pour les tickers sp√©cifi√©s.
        """
        st.markdown("### T√©l√©chargement des donn√©es historiques üìä")
        st.write("Nous collectons les donn√©es historiques des actifs sp√©cifi√©s depuis Yahoo Finance.")
        data_dict = {}
        missing_tickers = []

        for ticker, name in zip(self.tickers, self.names):
            try:
                data = yf.download(ticker, start=self.start_date)['Adj Close'].dropna()
                data_dict[ticker] = data
            except Exception as e:
                missing_tickers.append(ticker)

        if data_dict:
            self.data = pd.DataFrame(data_dict)
            self.returns = self.data.pct_change().dropna()

        if missing_tickers:
            st.error(f"Les tickers suivants n'ont pas pu √™tre t√©l√©charg√©s : {missing_tickers}")
        else:
            st.success("Toutes les donn√©es ont √©t√© t√©l√©charg√©es avec succ√®s!")

    def prepare_data(self):
        """
        Pr√©pare soigneusement les donn√©es :
        - Gestion des valeurs manquantes
        - V√©rification de la stationnarit√©
        - Transformation pour rendre les s√©ries stationnaires
        - D√©tection et gestion des outliers
        - Standardisation
        """
        st.markdown("### Pr√©paration des Donn√©es üîß")
        st.write("Nous pr√©parons maintenant les donn√©es pour les analyses suivantes, en v√©rifiant leur qualit√© et en les rendant utilisables pour les mod√®les pr√©dictifs.")
        self.handle_missing_data()
        self.check_stationarity()
        self.make_stationary()
        self.detect_outliers()
        self.scale_data()
        st.success("Pr√©paration des donn√©es termin√©e.")

    def handle_missing_data(self, method='linear'):
        """
        G√®re les valeurs manquantes dans les s√©ries temporelles.
        """
        self.data = self.data.interpolate(method=method).dropna()
        self.returns = self.data.pct_change().dropna()

    def check_stationarity(self):
        """
        Effectue un test de Dickey-Fuller Augment√© (ADF) pour v√©rifier la stationnarit√© des s√©ries temporelles.
        """
        st.write("**V√©rification de la stationnarit√© des s√©ries temporelles**")
        for column in self.data.columns:
            result = adfuller(self.data[column].dropna())
            if result[1] > 0.05:
                st.warning(f"La s√©rie pour {column} n'est pas stationnaire.")
            else:
                st.success(f"La s√©rie pour {column} est stationnaire.")

    def make_stationary(self):
        """
        Applique une diff√©renciation premi√®re pour rendre les s√©ries temporelles stationnaires.
        """
        self.returns = self.data.diff().dropna()

    def detect_outliers(self):
        """
        D√©tection des outliers dans les s√©ries temporelles via la m√©thode IQR.
        """
        st.write("**D√©tection et gestion des outliers**")
        Q1 = self.returns.quantile(0.25)
        Q3 = self.returns.quantile(0.75)
        IQR = Q3 - Q1
        outliers = (self.returns < (Q1 - 1.5 * IQR)) | (self.returns > (Q3 + 1.5 * IQR))
        st.write(f"Nombre d'outliers d√©tect√©s : {outliers.sum().sum()}")

    def scale_data(self):
        """
        Standardisation des donn√©es et mise √† la m√™me √©chelle.
        """
        scaler = StandardScaler()
        self.returns = pd.DataFrame(scaler.fit_transform(self.returns), index=self.returns.index, columns=self.returns.columns)
        min_max_scaler = MinMaxScaler()
        self.data = pd.DataFrame(min_max_scaler.fit_transform(self.data), index=self.data.index, columns=self.data.columns)
        st.write("**Les donn√©es ont √©t√© standardis√©es et mises √† la m√™me √©chelle**")

    def random_forest_model(self):
        """
        Construire un mod√®le For√™t Al√©atoire avec r√©gularisation L2 bas√© sur les meilleures d√©riv√©es et inverses des actifs, except√© Bitcoin, et afficher le R¬≤.
        """
        st.markdown("### Mod√®le For√™t Al√©atoire avec Meilleures D√©riv√©es et Inverses des Actifs üå≤")
        st.write("Nous construisons un mod√®le de For√™t Al√©atoire pour pr√©dire les rendements de Bitcoin en utilisant les meilleures d√©riv√©es et inverses des autres actifs, sans utiliser Bitcoin lui-m√™me.")

        # Pr√©paration des features : d√©riv√©es premi√®res, secondes et inverses des rendements
        best_features = {}
        for col in self.returns.columns:
            if col != 'BTC-USD':
                first_derivative = np.gradient(self.returns[col])
                second_derivative = np.gradient(first_derivative)
                inverse_returns = self.returns[col].apply(lambda x: 1/x if x != 0 else 0)

                best_features[f"Premi√®re D√©riv√©e de {col}"] = first_derivative
                best_features[f"Seconde D√©riv√©e de {col}"] = second_derivative
                best_features[f"Inverse des Rendements de {col}"] = inverse_returns

        # Cr√©er une matrice de donn√©es avec les meilleures d√©riv√©es et inverses s√©lectionn√©es
        X = pd.DataFrame(best_features, index=self.returns.index)
        y = self.returns['BTC-USD']

        # Mod√®le For√™t Al√©atoire avec r√©gularisation L2
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_features='sqrt')
        rf_model.fit(X, y)

        # Pr√©diction
        y_pred = rf_model.predict(X)

        # Calcul du R¬≤
        r_squared = r2_score(y, y_pred)
        st.write(f"**R¬≤ du mod√®le For√™t Al√©atoire :** {r_squared:.3f}")
        if r_squared > 0.7:
            st.success("Le mod√®le explique une grande partie de la variabilit√© des rendements de Bitcoin.")
        else:
            st.warning("Le mod√®le a une capacit√© limit√©e √† expliquer la variabilit√© des rendements de Bitcoin.")

        # Importance des features
        feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)
        feature_importances = feature_importances.sort_values(ascending=False)
        st.write("### Importance des Variables dans le Mod√®le For√™t Al√©atoire")
        st.write(feature_importances.head(10))

    def plot_significant_relationships(self):
        """
        Affiche des graphiques entre Bitcoin et chaque actif qui poss√®de une relation statistiquement significative.
        """
        st.markdown("### Visualisation des Relations Statistiquement Significatives üìä")
        st.write("Nous allons visualiser les relations entre Bitcoin et les autres actifs qui pr√©sentent une causalit√©, une co-int√©gration ou d'autres relations significatives.")
        significant_assets = []

        # V√©rification de la causalit√© de Granger
        for col in self.returns.columns:
            if col != 'BTC-USD':
                try:
                    test_result = grangercausalitytests(self.returns[['BTC-USD', col]], maxlag=5, verbose=False)
                    min_p_value = min(result[0]['ssr_ftest'][1] for result in test_result.values())
                    if min_p_value < 0.05:
                        significant_assets.append(col)
                        st.write(f"**{col} a une relation de causalit√© de Granger significative avec Bitcoin (p-value={min_p_value:.4f})**")
                except Exception as e:
                    st.warning(f"Probl√®me avec le test de Granger pour {col} : {e}")

        # V√©rification de la co-int√©gration avec un seuil de significativit√© de 0.01
        btc_prices = self.data['BTC-USD']
        for col in self.data.columns:
            if col != 'BTC-USD':
                _, pvalue, _ = coint(btc_prices, self.data[col])
                if pvalue < 0.01:
                    significant_assets.append(col)
                    st.write(f"**{col} est co-int√©gr√© avec Bitcoin (p-value={pvalue:.4f})**")

        # Suppression des doublons
        significant_assets = list(set(significant_assets))

        # Affichage des graphiques et g√©n√©ration des signaux de trading
        for col in significant_assets:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=self.data.index, y=self.data['BTC-USD'], mode='lines', name='Bitcoin (BTC)'))
            fig.add_trace(go.Scatter(x=self.data.index, y=self.data[col], mode='lines', name=self.names[self.tickers.index(col)]))
            fig.update_layout(title=f"Relation entre Bitcoin et {self.names[self.tickers.index(col)]}", xaxis_title="Date", yaxis_title="Prix (mis √† la m√™me √©chelle)", autosize=False, width=800, height=400)
            st.plotly_chart(fig)

            # G√©n√©ration de signaux de trading bas√©s sur la co-int√©gration
            signal = self.data['BTC-USD'] - self.data[col]
            buy_signal = signal < signal.quantile(0.25)
            sell_signal = signal > signal.quantile(0.75)

            st.write(f"**Signaux de trading pour la paire Bitcoin - {self.names[self.tickers.index(col)]}**")
            st.write(f"Nombre de signaux d'achat : {buy_signal.sum()} | Nombre de signaux de vente : {sell_signal.sum()}")

            # Calcul de la taille de position en fonction de l'Edge Ratio
            edge_ratio = (sell_signal.sum() - buy_signal.sum()) / (sell_signal.sum() + buy_signal.sum())
            position_size = edge_ratio * 100  # Exemple de calcul de taille de position en fonction de l'Edge Ratio
            st.write(f"**Taille de position sugg√©r√©e (en % du capital) :** {position_size:.2f}%")


def main():
    st.title("üí° Analyse des Relations entre Bitcoin et Autres Cryptomonnaies")
    st.write("Bienvenue dans cette application d'analyse financi√®re qui explore les liens entre Bitcoin et diverses cryptomonnaies.")

    # Liste des tickers et noms r√©els des cryptomonnaies
    tickers = [
        'BTC-USD', 'ETH-USD', 'BNB-USD', 'ADA-USD', 'SOL-USD', 'XRP-USD', 'DOGE-USD', 'DOT-USD', 'AVAX-USD',
        'MATIC-USD', 'LTC-USD', 'LINK-USD', 'UNI1-USD', 'ATOM-USD', 'XMR-USD', 'ALGO-USD', 'FIL-USD', 'VET-USD'
    ]
    
    # Noms r√©els des actifs financiers correspondants
    names = [
        'Bitcoin (BTC)', 'Ethereum (ETH)', 'Binance Coin (BNB)', 'Cardano (ADA)', 'Solana (SOL)',
        'Ripple (XRP)', 'Dogecoin (DOGE)', 'Polkadot (DOT)', 'Avalanche (AVAX)', 'Polygon (MATIC)',
        'Litecoin (LTC)', 'Chainlink (LINK)', 'Uniswap (UNI)', 'Cosmos (ATOM)', 'Monero (XMR)',
        'Algorand (ALGO)', 'Filecoin (FIL)', 'VeChain (VET)'
    ]

    start_date = '2018-01-01'

    analyzer = ComprehensiveCryptoCommoAnalyzer(tickers, names, start_date)

    st.header('1. T√©l√©chargement et Pr√©paration des Donn√©es')
    analyzer.fetch_data()
    
    # Pr√©paration rigoureuse des donn√©es
    analyzer.prepare_data()

    st.header('2. Mod√®le For√™t Al√©atoire avec Variables Significatives')
    analyzer.random_forest_model()

    st.header('3. Visualisation des Relations Statistiquement Significatives')
    analyzer.plot_significant_relationships()

if __name__ == "__main__":
    main()
