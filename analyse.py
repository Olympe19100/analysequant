import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from statsmodels.tsa.stattools import adfuller, coint
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
import plotly.graph_objects as go
import streamlit as st
import statsmodels.api as sm
from statsmodels.regression.linear_model import OLS

# Classe pour les strat√©gies de co-int√©gration simplifi√©es
class CointegrationStrategies:
    def __init__(self, data):
        self.data = data
        self.pairs = []
        self.coverage_ratios = {}
        self.spreads = {}

    def identify_cointegrated_pairs(self):
        """
        Identifie les paires d'actifs ayant une relation de co-int√©gration.
        """
        st.write("### Identification des paires d'actifs co-int√©gr√©es üìä")
        for i in range(len(self.data.columns)):
            for j in range(i + 1, len(self.data.columns)):
                asset1 = self.data.columns[i]
                asset2 = self.data.columns[j]
                _, pvalue, _ = coint(self.data[asset1], self.data[asset2])
                if pvalue < 0.05:
                    self.pairs.append((asset1, asset2))
                    st.write(f"**Paire d√©tect√©e : {asset1} et {asset2} (p-value={pvalue:.4f})**")

    def calculate_hedge_ratios(self):
        """
        Calcule le ratio de couverture pour chaque paire d√©tect√©e.
        """
        st.write("### Calcul des ratios de couverture (r√©gression lin√©aire) üìâ")
        for asset1, asset2 in self.pairs:
            model = OLS(self.data[asset1], sm.add_constant(self.data[asset2])).fit()
            self.coverage_ratios[(asset1, asset2)] = model.params[1]
            st.write(f"Ratio de couverture pour {asset1}/{asset2} : {model.params[1]:.4f}")
            
            # Trac√© de la droite de r√©gression
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=self.data[asset2], y=self.data[asset1], mode='markers', name='Donn√©es'))
            fig.add_trace(go.Scatter(x=self.data[asset2], y=model.fittedvalues, mode='lines', name='R√©gression Lin√©aire'))
            fig.update_layout(title=f"R√©gression Lin√©aire : {asset1} vs {asset2}", xaxis_title=asset2, yaxis_title=asset1)
            st.plotly_chart(fig)

    def calculate_spreads(self):
        """
        Calcule la diff√©rence (spread) entre deux actifs co-int√©gr√©s pour d√©tecter des opportunit√©s de trading.
        """
        st.write("### Calcul des spreads (√©carts) entre les actifs üìâ")
        for (asset1, asset2), ratio in self.coverage_ratios.items():
            self.spreads[(asset1, asset2)] = self.data[asset1] - ratio * self.data[asset2]
            st.write(f"Spread calcul√© pour la paire {asset1}/{asset2}")

    def generate_signals(self):
        """
        G√©n√®re des signaux de trading en fonction du comportement du spread.
        """
        st.write("### Signaux de Trading üö¶")
        for (asset1, asset2), spread in self.spreads.items():
            z_score = (spread - spread.mean()) / spread.std()
            buy_signal = z_score < -2
            sell_signal = z_score > 2

            st.write(f"**Signaux de Trading pour {asset1}/{asset2} :**")
            st.write(f"Signaux d'achat : {buy_signal.sum()}, Signaux de vente : {sell_signal.sum()}")

# Classe principale pour g√©rer l'analyse et la pr√©paration des donn√©es
class SimpleCryptoAnalyzer:
    def __init__(self, tickers, names, start_date):
        self.tickers = tickers
        self.names = names
        self.start_date = start_date
        self.data = None
        self.returns = None

    def fetch_data(self):
        """
        T√©l√©charge les donn√©es historiques des actifs.
        """
        st.markdown("### T√©l√©chargement des donn√©es üìä")
        data_dict = {}
        missing_tickers = []

        for ticker, name in zip(self.tickers, self.names):
            try:
                data = yf.download(ticker, start=self.start_date)['Adj Close'].dropna()
                data_dict[ticker] = data
            except Exception as e:
                missing_tickers.append(ticker)

        if data_dict:
            self.data = pd.DataFrame(data_dict)
            self.returns = self.data.pct_change().dropna()

        if missing_tickers:
            st.error(f"Les tickers suivants n'ont pas pu √™tre t√©l√©charg√©s : {missing_tickers}")
        else:
            st.success("Toutes les donn√©es ont √©t√© t√©l√©charg√©es avec succ√®s!")

    def prepare_data(self):
        """
        Pr√©pare soigneusement les donn√©es :
        - Gestion des valeurs manquantes
        - V√©rification de la stationnarit√©
        - Transformation des donn√©es
        - Standardisation
        """
        st.markdown("### Pr√©paration des donn√©es üìä")
        self.handle_missing_data()
        self.check_stationarity()
        self.make_stationary()
        self.scale_data()
        st.success("Pr√©paration des donn√©es termin√©e.")

    def handle_missing_data(self):
        """
        G√®re les valeurs manquantes en utilisant une interpolation lin√©aire.
        """
        self.data = self.data.interpolate(method='linear').dropna()
        self.returns = self.data.pct_change().dropna()

    def check_stationarity(self):
        """
        V√©rifie si les donn√©es sont stationnaires √† l'aide du test ADF.
        """
        st.write("**V√©rification de la stationnarit√©**")
        for column in self.data.columns:
            result = adfuller(self.data[column].dropna())
            if result[1] > 0.05:
                st.warning(f"La s√©rie pour {column} n'est pas stationnaire.")
            else:
                st.success(f"La s√©rie pour {column} est stationnaire.")

    def make_stationary(self):
        """
        Rends les donn√©es stationnaires en appliquant la diff√©renciation.
        """
        self.returns = self.data.diff().dropna()

    def scale_data(self):
        """
        Standardisation des donn√©es pour les mettre √† la m√™me √©chelle.
        """
        scaler = StandardScaler()
        self.returns = pd.DataFrame(scaler.fit_transform(self.returns), index=self.returns.index, columns=self.returns.columns)
        st.write("**Donn√©es standardis√©es**")

    def random_forest_model(self):
        """
        Cr√©e un mod√®le pr√©dictif pour Bitcoin bas√© sur les autres cryptomonnaies.
        """
        st.markdown("### Mod√®le de pr√©diction üå≤")
        st.write("Nous utilisons un mod√®le pour pr√©dire les rendements du Bitcoin.")

        # Pr√©paration des donn√©es
        X = self.returns.drop(columns=['BTC-USD'])
        y = self.returns['BTC-USD']

        # Mod√®le de For√™t Al√©atoire
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_model.fit(X, y)

        # Pr√©diction et √©valuation
        y_pred = rf_model.predict(X)
        r_squared = r2_score(y, y_pred)
        st.write(f"**R¬≤ du mod√®le For√™t Al√©atoire :** {r_squared:.3f}")
        st.write("Plus le R¬≤ est proche de 1, plus le mod√®le est performant.")

        # Importance des variables
        feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)
        st.write("### Importance des Variables dans le Mod√®le")
        st.write(feature_importances.sort_values(ascending=False))

def main():
    st.title("üîç Analyse Simplifi√©e des Cryptomonnaies")
    st.write("Cette application permet d'explorer les relations entre Bitcoin et d'autres cryptomonnaies, et de g√©n√©rer des signaux de trading bas√©s sur des strat√©gies simplifi√©es.")

    # Liste des tickers et noms r√©els des cryptomonnaies
    tickers = [
        'BTC-USD', 'ETH-USD', 'BNB-USD', 'ADA-USD', 'SOL-USD', 'XRP-USD', 'DOGE-USD', 'DOT-USD', 'AVAX-USD'
    ]
    
    # Noms r√©els des actifs financiers correspondants
    names = [
        'Bitcoin (BTC)', 'Ethereum (ETH)', 'Binance Coin (BNB)', 'Cardano (ADA)', 'Solana (SOL)',
        'Ripple (XRP)', 'Dogecoin (DOGE)', 'Polkadot (DOT)', 'Avalanche (AVAX)'
    ]

    start_date = '2018-01-01'

    analyzer = SimpleCryptoAnalyzer(tickers, names, start_date)

    st.header('1. T√©l√©chargement et Pr√©paration des Donn√©es')
    analyzer.fetch_data()
    analyzer.prepare_data()

    st.header('2. Mod√®le Pr√©dictif Bitcoin')
    analyzer.random_forest_model()

    st.header('3. Strat√©gies de Co-Int√©gration')
    cointegration = CointegrationStrategies(analyzer.data)
    cointegration.identify_cointegrated_pairs()
    cointegration.calculate_hedge_ratios()
    cointegration.calculate_spreads()
    cointegration.generate_signals()

if __name__ == "__main__":
    main()
