import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from statsmodels.tsa.stattools import adfuller, grangercausalitytests, coint
from sklearn.feature_selection import mutual_info_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score
import plotly.graph_objects as go
import streamlit as st
import statsmodels.api as sm
import scipy.stats as stats
from statsmodels.regression.linear_model import OLS

st.set_page_config(page_title="Analyse Crypto", page_icon="ğŸ“Š", layout="wide")

st.markdown("""
    <style>
    .big-font {
        font-size:50px !important;
        color: #1E90FF;
        text-align: center;
    }
    .subheader {
        font-size:30px;
        color: #4682B4;
    }
    .info-box {
        background-color: #E6F3FF;
        padding: 20px;
        border-radius: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

st.markdown('<p class="big-font">ğŸ“Š Analyse Crypto AvancÃ©e</p>', unsafe_allow_html=True)

# Classe pour les stratÃ©gies de co-intÃ©gration
class CointegrationStrategies:
    def __init__(self, data):
        self.data = data
        self.pairs = []
        self.coverage_ratios = {}
        self.spreads = {}

    def identify_cointegrated_pairs(self):
        st.markdown('<p class="subheader">Identification des paires co-intÃ©grÃ©es ğŸ”</p>', unsafe_allow_html=True)
        for i in range(len(self.data.columns)):
            for j in range(i + 1, len(self.data.columns)):
                asset1 = self.data.columns[i]
                asset2 = self.data.columns[j]
                _, pvalue, _ = coint(self.data[asset1], self.data[asset2])
                if pvalue < 0.05:
                    self.pairs.append((asset1, asset2))
                    st.info(f"**Paire co-intÃ©grÃ©e : {asset1} et {asset2} (p-value={pvalue:.4f})**")

    def calculate_hedge_ratios(self):
        st.markdown('<p class="subheader">Calcul des ratios de couverture ğŸ“Š</p>', unsafe_allow_html=True)
        for asset1, asset2 in self.pairs:
            model = OLS(self.data[asset1], sm.add_constant(self.data[asset2])).fit()
            self.coverage_ratios[(asset1, asset2)] = model.params[1]
            st.write(f"Ratio de couverture pour {asset1}/{asset2} : {model.params[1]:.4f}")

    def calculate_spreads(self):
        st.markdown('<p class="subheader">Calcul des spreads ğŸ“‰</p>', unsafe_allow_html=True)
        for (asset1, asset2), ratio in self.coverage_ratios.items():
            self.spreads[(asset1, asset2)] = self.data[asset1] - ratio * self.data[asset2]
            st.write(f"Spread calculÃ© pour la paire {asset1}/{asset2}")

    def generate_signals(self):
        st.markdown('<p class="subheader">GÃ©nÃ©ration des signaux de trading ğŸš¦</p>', unsafe_allow_html=True)
        for (asset1, asset2), spread in self.spreads.items():
            z_score = (spread - spread.mean()) / spread.std()
            buy_signal = z_score < -2
            sell_signal = z_score > 2
            st.markdown(f"<div class='info-box'><h3>Signaux pour {asset1}/{asset2} :</h3>"
                        f"Nombre de signaux d'achat : {buy_signal.sum()}<br>"
                        f"Nombre de signaux de vente : {sell_signal.sum()}<br>"
                        f"Taille de position suggÃ©rÃ©e : {((sell_signal.sum() - buy_signal.sum()) / (sell_signal.sum() + buy_signal.sum()) * 100):.2f}%"
                        "</div>", unsafe_allow_html=True)

# Classe principale d'analyse
class ComprehensiveCryptoCommoAnalyzer:
    def __init__(self, tickers, names, start_date):
        self.tickers = tickers
        self.names = names
        self.start_date = start_date
        self.data = None
        self.returns = None
        self.significant_vars = []
        self.cointegration = None

    def fetch_data(self):
        st.markdown('<p class="subheader">TÃ©lÃ©chargement des donnÃ©es historiques ğŸ“Š</p>', unsafe_allow_html=True)
        data_dict = {}
        missing_tickers = []
        for ticker, name in zip(self.tickers, self.names):
            try:
                data = yf.download(ticker, start=self.start_date)['Adj Close'].dropna()
                data_dict[ticker] = data
            except Exception as e:
                missing_tickers.append(ticker)
        
        if data_dict:
            self.data = pd.DataFrame(data_dict)
            self.returns = self.data.pct_change().dropna()
            if missing_tickers:
                st.error(f"Les tickers suivants n'ont pas pu Ãªtre tÃ©lÃ©chargÃ©s : {missing_tickers}")
            else:
                st.success("Toutes les donnÃ©es ont Ã©tÃ© tÃ©lÃ©chargÃ©es avec succÃ¨s!")

    def prepare_data(self):
        st.markdown('<p class="subheader">PrÃ©paration des DonnÃ©es ğŸ”§</p>', unsafe_allow_html=True)
        self.handle_missing_data()
        self.check_stationarity()
        self.make_stationary()
        self.detect_outliers()
        self.scale_data()
        st.success("PrÃ©paration des donnÃ©es terminÃ©e.")

    def handle_missing_data(self, method='linear'):
        self.data = self.data.interpolate(method=method).dropna()
        self.returns = self.data.pct_change().dropna()

    def check_stationarity(self):
        st.write("**VÃ©rification de la stationnaritÃ© des sÃ©ries temporelles**")
        for column in self.data.columns:
            result = adfuller(self.data[column].dropna())
            if result[1] > 0.05:
                st.warning(f"La sÃ©rie pour {column} n'est pas stationnaire.")
            else:
                st.success(f"La sÃ©rie pour {column} est stationnaire.")

    def make_stationary(self):
        self.returns = self.data.diff().dropna()

    def detect_outliers(self):
        st.write("**DÃ©tection et gestion des outliers**")
        Q1 = self.returns.quantile(0.25)
        Q3 = self.returns.quantile(0.75)
        IQR = Q3 - Q1
        outliers = (self.returns < (Q1 - 1.5 * IQR)) | (self.returns > (Q3 + 1.5 * IQR))
        st.write(f"Nombre d'outliers dÃ©tectÃ©s : {outliers.sum().sum()}")

    def scale_data(self):
        scaler = StandardScaler()
        self.returns = pd.DataFrame(scaler.fit_transform(self.returns), index=self.returns.index, columns=self.returns.columns)
        
        min_max_scaler = MinMaxScaler()
        self.data = pd.DataFrame(min_max_scaler.fit_transform(self.data), index=self.data.index, columns=self.data.columns)
        
        st.write("**Les donnÃ©es ont Ã©tÃ© standardisÃ©es et mises Ã  la mÃªme Ã©chelle**")

    def random_forest_model(self):
        st.markdown('<p class="subheader">ModÃ¨le ForÃªt AlÃ©atoire ğŸŒ²</p>', unsafe_allow_html=True)
        
        best_features = {}
        for col in self.returns.columns:
            if col != 'BTC-USD':
                first_derivative = np.gradient(self.returns[col])
                second_derivative = np.gradient(first_derivative)
                inverse_returns = self.returns[col].apply(lambda x: 1/x if x != 0 else 0)
                best_features[f"PremiÃ¨re DÃ©rivÃ©e de {col}"] = first_derivative
                best_features[f"Seconde DÃ©rivÃ©e de {col}"] = second_derivative
                best_features[f"Inverse des Rendements de {col}"] = inverse_returns
        
        X = pd.DataFrame(best_features, index=self.returns.index)
        y = self.returns['BTC-USD']
        
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_features='sqrt')
        rf_model.fit(X, y)
        
        y_pred = rf_model.predict(X)
        r_squared = r2_score(y, y_pred)
        
        st.markdown(f"<div class='info-box'><h3>RÃ©sultats du modÃ¨le :</h3>"
                    f"R2 du modÃ¨le ForÃªt AlÃ©atoire : {r_squared:.3f}<br>"
                    f"{'Le modÃ¨le explique une grande partie de la variabilitÃ© des rendements de Bitcoin.' if r_squared > 0.7 else 'Le modÃ¨le a une capacitÃ© limitÃ©e Ã  expliquer la variabilitÃ© des rendements de Bitcoin.'}"
                    "</div>", unsafe_allow_html=True)
        
        feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)
        feature_importances = feature_importances.sort_values(ascending=False)
        
        st.write("### Importance des Variables dans le ModÃ¨le ForÃªt AlÃ©atoire")
        st.write(feature_importances.head(10))

    def plot_significant_relationships(self):
        st.markdown('<p class="subheader">Visualisation des Relations Statistiquement Significatives ğŸ“Š</p>', unsafe_allow_html=True)
        
        significant_assets = []
        
        for col in self.returns.columns:
            if col != 'BTC-USD':
                try:
                    test_result = grangercausalitytests(self.returns[['BTC-USD', col]], maxlag=5, verbose=False)
                    min_p_value = min(result[0]['ssr_ftest'][1] for result in test_result.values())
                    if min_p_value < 0.05:
                        significant_assets.append(col)
                        st.info(f"**{col} a une relation de causalitÃ© de Granger significative avec Bitcoin (p-value={min_p_value:.4f})**")
                except Exception as e:
                    st.warning(f"ProblÃ¨me avec le test de Granger pour {col} : {e}")
        
        btc_prices = self.data['BTC-USD']
        for col in self.data.columns:
            if col != 'BTC-USD':
                _, pvalue, _ = coint(btc_prices, self.data[col])
                if pvalue < 0.01:
                    significant_assets.append(col)
                    st.info(f"**{col} est co-intÃ©grÃ© avec Bitcoin (p-value={pvalue:.4f})**")
        
        significant_assets = list(set(significant_assets))
        
        for col in significant_assets:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=self.data.index, y=self.data['BTC-USD'], mode='lines', name='Bitcoin (BTC)'))
            fig.add_trace(go.Scatter(x=self.data.index, y=self.data[col], mode='lines', name=self.names[self.tickers.index(col)]))
            fig.update_layout(title=f"Relation entre Bitcoin et {self.names[self.tickers.index(col)]}", 
                              xaxis_title="Date", yaxis_title="Prix (mis Ã  la mÃªme Ã©chelle)", 
                              autosize=False, width=800, height=400)
            st.plotly_chart(fig)
            
            signal = self.data['BTC-USD'] - self.data[col]
            buy_signal = signal < signal.quantile(0.25)
            sell_signal = signal > signal.quantile(0.75)
            
            st.markdown(f"<div class='info-box'><h3>Signaux de trading pour la paire Bitcoin - {self.names[self.tickers.index(col)]} :</h3>"
                        f"Nombre de signaux d'achat : {buy_signal.sum()}<br>"
                        f"Nombre de signaux de vente : {sell_signal.sum()}<br>"
                        f"Taille de position suggÃ©rÃ©e : {((sell_signal.sum() - buy_signal.sum()) / (sell_signal.sum() + buy_signal.sum()) * 100):.2f}%"
                        "</div>", unsafe_allow_html=True)

# Fonction principale Streamlit
def main():
    st.sidebar.header("ğŸ“Œ Navigation")
    page = st.sidebar.radio("Choisissez une section :", ["Accueil", "Analyse des donnÃ©es", "ModÃ©lisation", "Visualisation"])

    tickers = ['BTC-USD', 'ETH-USD', 'BNB-USD', 'ADA-USD', 'SOL-USD', 'XRP-USD', 'DOGE-USD']
    names = ['Bitcoin', 'Ethereum', 'Binance Coin', 'Cardano', 'Solana', 'Ripple', 'Dogecoin']
    
    start_date = st.sidebar.date_input("Date de dÃ©but de l'analyse :", value=pd.to_datetime("2020-01-01"))
    
    analyzer = ComprehensiveCryptoCommoAnalyzer(tickers, names, start_date)

    if page == "Accueil":
        st.write("## Bienvenue dans l'analyseur de cryptomonnaies ! ğŸ‘‹")
        st.write("Cet outil vous aide Ã  comprendre les relations entre Bitcoin et d'autres cryptomonnaies.")
        st.info("ğŸ‘ˆ Utilisez le menu Ã  gauche pour naviguer entre les diffÃ©rentes sections.")

    elif page == "Analyse des donnÃ©es":
        analyzer.fetch_data()
        analyzer.prepare_data()

    elif page == "ModÃ©lisation":
        analyzer.fetch_data()
        analyzer.prepare_data()
        analyzer.random_forest_model()

    elif page == "Visualisation":
        analyzer.fetch_data()
        analyzer.prepare_data()
        analyzer.plot_significant_relationships()

if __name__ == "__main__":
    main()
